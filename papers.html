<ul class="publication-list">
    <li id="paper5">
      <p>
        <strong style="color: black;">[<span style="color: #1e90ff;">5</span>] Path-metrics, pruning and generalization</strong>
        <span style="color: black;"><em><u>Antoine Gonon</u>, Nicolas Brisebarre, Elisa Riccietti, Rémi Gribonval</em></span>
      </p>
      <p>
        <i>Preprint. Under review. (2024)</i>,
        <a href="https://arxiv.org/abs/2405.15006" style="color: blue;">Paper</a>
      </p>
    </li>
    <li id="paper4">
      <p>
        <strong style="color: black;">[<span style="color: #1e90ff;">4</span>] Make Inference Faster: Efficient GPU Memory Management for Butterfly Sparse Matrix Multiplication</strong>
        <span style="color: black;"><em><u>Antoine Gonon</u>, Léon Zheng, Pascal Carrivain, Quoc-Tung Le</em></span>
      </p>
      <p>
        <i>Preprint. Under review. (2024)</i>,
        <a href="https://arxiv.org/abs/2405.15013" style="color: blue;">Paper</a>
      </p>
    </li>
    <li id="paper3">
      <p>
        <strong style="color: black;">[<span style="color: #1e90ff;">3</span>] A path-norm toolkit for modern networks: consequences, promises and challenges</strong>
        <span style="color: black;"><em><u>Antoine Gonon</u>, Nicolas Brisebarre, Elisa Riccietti, Rémi Gribonval</em></span>
      </p>
      <p>
        <i>ICLR Spotlight (2024)</i>,
        <a href="https://arxiv.org/abs/2310.01225" style="color: blue;">Paper</a> |
        <a href="materials/posters/poster_path_norm_toolkit.pdf" style="color: blue;">Poster</a> |
        <a href="https://github.com/agonon/pathnorm_toolkit" style="color: blue;">Code</a>
      </p>
    </li>
    <li id="paper2">
      <p>
        <strong style="color: black;">[<span style="color: #1e90ff;">2</span>] Can sparsity improve the privacy of neural networks?</strong>
        <span style="color: black;"><em><u>Antoine Gonon</u>, Léon Zheng, Clément Lalanne, Quoc-Tung Le, Guillaume Lauga, Can Pouliquen</em></span>
      </p>
      <p>
        <i>Gretsi: French National Conference of Signal Processing (2023)</i>,
        <a href="https://hal.science/hal-04062317" style="color: blue;">Paper</a>
      </p>
    </li>
    <li id="paper1">
      <p>
        <strong style="color: black;">[<span style="color: #1e90ff;">1</span>] Approximation speed of quantized vs. unquantized ReLU neural networks and beyond</strong>
        <span style="color: black;"><em><u>Antoine Gonon</u>, Nicolas Brisebarre, Elisa Riccietti, Rémi Gribonval</em></span>
      </p>
      <p>
        <i>IEEE Transactions on Information Theory (2023)</i>,
        <a href="https://arxiv.org/abs/2205.11874" style="color: blue;">Paper</a> |
        <a href="materials/slides/slides_approximation_quantized_nn_1.pdf" style="color: blue;">Slides 1</a> |
        <a href="materials/slides/slides_approximation_quantized_nn_2.pdf" style="color: blue;">Slides 2</a> |
        <a href="materials/posters/poster_approximation_quantized_nn.pdf" style="color: blue;">Poster</a>
      </p>
    </li>
  </ul>
